{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b627465b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: prior=0.545, mean=[3.53333333e+01 5.63333333e+04], std=[1.19443152e+01 3.92003401e+04], likelihoods=[1.90345547e-02 9.34487222e-07], unnorm posterior=9.702299e-09\n",
      "Class 1: prior=0.455, mean=[4.080e+01 1.254e+05], std=[1.4131525e+01 6.1528855e+04], likelihoods=[2.47943036e-02 6.25209496e-06], unnorm posterior=7.046197e-08\n",
      "\n",
      "Normalized posterior probabilities: {np.int64(0): np.float64(0.1210302140212407), np.int64(1): np.float64(0.8789697859787593)}\n",
      "\n",
      "Predicted class for sample [48, 142000]: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([\n",
    "    [25, 40000],\n",
    "    [35, 60000],\n",
    "    [45, 80000],\n",
    "    [20, 20000],\n",
    "    [35, 120000],\n",
    "    [52, 18000],\n",
    "    [23, 95000],\n",
    "    [40, 62000],\n",
    "    [60, 100000],\n",
    "    [48, 220000],\n",
    "    [33, 150000]\n",
    "])\n",
    "Y = np.array([0,0,0,0,0,0,1,1,1,1,1])\n",
    "\n",
    "x_test = np.array([48, 142000])\n",
    "\n",
    "classes = np.unique(Y)\n",
    "stats = {}\n",
    "for c in classes:\n",
    "    Xc = X[Y == c]\n",
    "    stats[c] = {\n",
    "        'prior': Xc.shape[0] / X.shape[0],\n",
    "        'mean': Xc.mean(axis=0),\n",
    "        'std': Xc.std(axis=0, ddof=1) \n",
    "    }\n",
    "\n",
    "def gaussian_pdf(x, mean, std):\n",
    "    return (1 / (np.sqrt(2 * np.pi) * std)) * np.exp(-((x - mean) ** 2) / (2 * std ** 2))\n",
    "\n",
    "posteriors = {}\n",
    "for c in classes:\n",
    "    prior = stats[c]['prior']\n",
    "    mean = stats[c]['mean']\n",
    "    std = stats[c]['std']\n",
    "    likelihoods = gaussian_pdf(x_test, mean, std)\n",
    "    likelihood = np.prod(likelihoods)\n",
    "    posterior_unnorm = prior * likelihood\n",
    "    posteriors[c] = posterior_unnorm\n",
    "    print(f\"Class {c}: prior={prior:.3f}, mean={mean}, std={std}, likelihoods={likelihoods}, unnorm posterior={posterior_unnorm:.6e}\")\n",
    "\n",
    "total = sum(posteriors.values())\n",
    "post_norm = {c: posteriors[c]/total for c in classes}\n",
    "\n",
    "print(\"\\nNormalized posterior probabilities:\", post_norm)\n",
    "predicted = max(post_norm, key=post_norm.get)\n",
    "print(f\"\\nPredicted class for sample {x_test.tolist()}: {predicted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad47a710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Fold-1: 76.30208333333334 %\n",
      "Accuracy Fold-2: 73.4375 %\n",
      "Average Accuracy: 74.86979166666667 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt, pi, exp\n",
    "\n",
    "df = pd.read_csv(\"diabetes.csv\")  \n",
    "\n",
    "\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "data = np.hstack((X, y.reshape(-1,1)))\n",
    "\n",
    "def summarize_by_class(X_train, y_train):\n",
    "    classes = np.unique(y_train)\n",
    "    summaries = {}\n",
    "    priors = {}\n",
    "    total_samples = len(y_train)\n",
    "\n",
    "    for c in classes:\n",
    "        X_c = X_train[y_train == c]\n",
    "        priors[c] = len(X_c) / total_samples\n",
    "        means = X_c.mean(axis=0)\n",
    "        variances = X_c.var(axis=0) + 1e-9   \n",
    "        summaries[c] = (means, variances)\n",
    "\n",
    "    return summaries, priors\n",
    "\n",
    "def gaussian_pdf(x, mean, var):\n",
    "    return (1 / sqrt(2 * pi * var)) * exp(-((x - mean)**2) / (2 * var))\n",
    "\n",
    "def predict_sample(x, summaries, priors):\n",
    "    posteriors = {}\n",
    "\n",
    "    for c, (means, variances) in summaries.items():\n",
    "        prior = priors[c]\n",
    "        likelihood = 1\n",
    "        for i in range(len(x)):\n",
    "            likelihood *= gaussian_pdf(x[i], means[i], variances[i])\n",
    "        posteriors[c] = prior * likelihood\n",
    "\n",
    "    return max(posteriors, key=posteriors.get)\n",
    "\n",
    "np.random.shuffle(data)\n",
    "fold_size = len(data) // 2\n",
    "\n",
    "fold1 = data[:fold_size]\n",
    "fold2 = data[fold_size:]\n",
    "\n",
    "def evaluate(train, test):\n",
    "    X_train, y_train = train[:, :-1], train[:, -1]\n",
    "    X_test, y_test = test[:, :-1], test[:, -1]\n",
    "\n",
    "    summaries, priors = summarize_by_class(X_train, y_train)\n",
    "\n",
    "    predictions = []\n",
    "    for sample in X_test:\n",
    "        predictions.append(predict_sample(sample, summaries, priors))\n",
    "\n",
    "    accuracy = np.mean(predictions == y_test) * 100\n",
    "    return accuracy\n",
    "\n",
    "acc1 = evaluate(fold1, fold2)\n",
    "acc2 = evaluate(fold2, fold1)\n",
    "\n",
    "print(\"Accuracy Fold-1:\", acc1, \"%\")\n",
    "print(\"Accuracy Fold-2:\", acc2, \"%\")\n",
    "print(\"Average Accuracy:\", (acc1 + acc2)/2, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1037480c",
   "metadata": {},
   "source": [
    "Na√Øve Bayes assumes conditional independence between features and therefore uses only feature-wise likelihoods. It is simple, fast, and works well when features are independent or the dataset is small.\n",
    "\n",
    "The Multivariate Bayesian Classification Model (e.g., QDA, LDA) uses a full covariance matrix to model feature interactions and correlations. It is more powerful but requires more data and computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0550c2a6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
